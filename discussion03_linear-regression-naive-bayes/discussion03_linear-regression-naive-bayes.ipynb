{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "$$ \\text{LaTeX command declarations here.}\n",
    "\\newcommand{\\R}{\\mathbb{R}}\n",
    "\\renewcommand{\\vec}[1]{\\mathbf{#1}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# EECS445 Machine Learning\n",
    "## Discussion 03:  Linear Regression & Naive Bayes\n",
    "Written by Zhao Fu; Edited by Chansoo Lee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Linear Regression: Notations\n",
    "\n",
    "- Let vector $\\vec{x}_n \\in \\mathbb{R}^D$ denote the $n\\text{th}$ data. $D$ denotes number of attributes in dataset.\n",
    "- Let vector $\\phi(\\vec{x}_n) \\in \\mathbb{R}^M$ denote features for data $\\vec{x}_n$. $\\phi_j(\\vec{x}_n)$ denotes the $j\\text{th}$ feature for data $x_n$.\n",
    "- Feature $\\phi(\\vec{x}_n)$ is the *artificial* features which represents the preprocessing step. $\\phi(\\vec{x}_n)$ is usually some combination of transformations of $\\vec{x}_n$. For example, $\\phi(\\vec{x})$ could be vector constructed by $[\\vec{x}_n^T, \\cos(\\vec{x}_n)^T, \\exp(\\vec{x}_n)^T]^T$. If we do nothing to $\\vec{x}_n$, then $\\phi(\\vec{x}_n)=\\vec{x}_n$.\n",
    "- Continuous-valued label vector $t \\in \\mathbb{R}^N$ (target values). $t_n \\in \\mathbb{R}$ denotes the target value for $i\\text{th}$ data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recall: Least Squares Error Function\n",
    "- We will find the solution $\\vec{w}$ to linear regression by minimizing a cost/objective function.\n",
    "- When the objective function is sum of squared errors (sum differences between target $t$ and prediction $y$ over entire training data), this approach is also called **least squares**.\n",
    "- The objective function is \n",
    "$$\n",
    "\\begin{aligned}\n",
    "E(\\vec{w}) \n",
    "&= \\frac12 \\sum_{n=1}^N (y(\\vec{x}_n, \\vec{w}) - t_n)^2 \\\\\n",
    "&= \\frac12 \\sum_{n=1}^N \\left( \\sum_{j=0}^{M-1} w_j\\phi_j(\\vec{x}_n) - t_n \\right)^2 \\\\\n",
    "&= \\frac12 \\sum_{n=1}^N \\left( \\vec{w}^T \\phi(\\vec{x}_n) - t_n \\right)^2 \\\\\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 3.1\n",
    "Consider a data set in which each data point $t_n$ is associated with a weighting factor $r_n > 0$, so that the sum-of-squares error function becomes\n",
    "$$\n",
    "E(\\vec{w}; \\vec{r}) = \\frac12 \\sum_{n=1}^N r_n\\left(\\vec{w}^T \\phi(\\vec{x}_n) - t_n \\right)^2\n",
    "$$\n",
    "\n",
    "Find an expression for the solution $\\vec{w}^*$ that minimizes this error function. Give two\n",
    "alternative interpretations of the weighted sum-of-squares error function in terms of\n",
    "(i) data dependent noise variance and (ii) replicated data points.\n",
    "\n",
    "#### Solution (Matrix Calculus)\n",
    "\n",
    "We can write the above error function as \n",
    "$E(\\vec{w};\\vec{r}) = \\frac{1}{2} \\|S(\\Phi \\vec{w} - t)\\|_2^2$\n",
    "where $S$ is an $N$-by-$N$ diagonal matrix with entries $\\sqrt{r_n}$. Note $S^\\top S = S S^\\top$ is a diagonal matrix ($N$-by-$N$) with entries $r_n$. We denote $R = S^\\top S$. We also know that\n",
    "\n",
    "Similarly to hands-on lecture 4, $\\frac{1}{2}\\|S(\\Phi \\vec{w} - t)\\|_2^2 = \\frac{1}{2}(\\vec{w}^\\top (S \\Phi)^\\top S^\\top (S \\Phi) \\vec{w} - 2\\vec{w}^\\top \\Phi^\\top S^\\top S t - t^\\top t)$, and thus\n",
    "$$\\frac{\\partial E}{\\partial \\vec{w}} = \\Phi^\\top R \\Phi \\vec{w} - \\Phi^\\top R t.$$\n",
    "\n",
    "By setting it equal to 0, we have the closed form solution $\\vec{w} = (\\Phi^\\top R \\Phi)^{-1}\\Phi^\\top Rt$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Model Selection: Cross Validation\n",
    "Suppose we are using the following linear regression model to fit a dataset\n",
    "$$h_\\theta(x) = \\sum_{i=0}^{k}{\\theta_i \\phi_i(x)}$$\n",
    "where $\\phi_i(x) = x^i$, and wish to decide if $k$ should be $0, 1, \\dots,$ or $10$. How can we automatically select a model?\n",
    "\n",
    "For the sake of concreteness, we assume we have some finite set of models $M = \\{M_1,\\dots, M_d\\}$ that we’re trying to select among.\n",
    "For instance, in our first example above, the model $M_i$ would be an $i$th order polynomial regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Model Selection: Hold-out Cross Validation\n",
    "\n",
    "Suppose we have a training dataset $S$.\n",
    "\n",
    "In hold-out cross validation(also called simple cross validation), we do the following:\n",
    "1. Randomly split $S$ into $S_{train}$ (say, 70% of the data) and $S_{cv}$ (the remaining 30%). Here, $S_{cv}$ is called the hold-out cross validation set.\n",
    "2. Train each model $M_i$ on $S_{train}$ only, to get some hypothesis.\n",
    "3. Select and output the hypothesis that had the smallest error $\\epsilon_{S_{cv}}$ on the hold out cross validation set. (Recall, $\\epsilon_{S_{cv}}$ denotes the empirical error on the set of examples in Scv.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Model Selection: K-Fold Cross Validation\n",
    "\n",
    "Here is a method, called k-fold cross validation, that holds out less data each time:\n",
    "1. Randomly split $S$ into $k$ disjoint subsets of $m/k$ training examples each. Let’s call these subsets $S_1,\\dots, S_k$.\n",
    "2. For each model $M_i$, we evaluate it as follows:\n",
    "For $j = 1,\\dots, k$\n",
    "Train the model $M_i$ on $S_1 \\cup \\cdots \\cup S_{j−1} \\cup S_{j+1} \\cup \\cdots S_k$ (i.e., train on all the data except $S_j$) to get some hypothesis $h_{ij}$. Test the hypothesis $h_{ij}$ on $S_j$, to get $\\epsilon_{S_j}(h_{ij})$. The estimated generalization error of model $M_i$ is then calculated as the average of the $\\epsilon_{S_j}(h_{ij})$, which is $ \\frac{1}{k}\\sum_{j}{\\epsilon_{S_j}(h_{ij})}$.\n",
    "3. Pick the model $M_i$ with the lowest estimated generalization error, and retrain that model on the entire training set $S$. The resulting hypothesis is then output as our final answer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bayesian Linear Regression\n",
    "Recall **Maximum Likelihood Estimator(MLE)** for least square regression:\n",
    "\n",
    "Given $\\{ \\vec{x}_n, t_n \\}_{n=1}^N$, we want to find $\\vec{w}_{ML}$ that maximizes data likelihood function\n",
    "$$\n",
    "\\vec{w}_{ML}\n",
    "=\\arg \\max p(\\vec{t}|\\mathcal{X},\\vec{w},\\beta)\n",
    "=\\arg \\max \\prod_{n=1}^N \\mathcal{N}(t_n|\\vec{w}^T\\phi(\\vec{x}_n),\\beta^{-1})\n",
    "$$\n",
    "and by derivation we have shown in lecture $\\vec{w}_{ML}$ is equivalent to the least squares solution $\\hat{\\vec{w}} = \\Phi^\\dagger \\vec{t}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bayesian Linear Regression\n",
    "Recall **MAP Estimator** for least square regression:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\vec{w}_{MAP} \n",
    "&= \\arg \\max p(\\vec{w}|\\vec{t}, \\mathcal{X},\\beta) & & (\\text{Posteriori Probability})\\\\\n",
    "&= \\arg \\max \\frac{p(\\vec{w}, \\vec{t}, \\mathcal{X},\\beta)}{p(\\mathcal{X}, t, \\beta)} \\\\\n",
    "&= \\arg \\max \\frac{p(\\vec{t}|\\vec{w}, \\mathcal{X},\\beta) p(\\vec{w}, \\mathcal{X}, \\beta)}{p(\\mathcal{X}, t, \\beta)} \\\\\n",
    "&= \\arg \\max p(\\vec{t}|\\vec{w}, \\mathcal{X},\\beta) p(\\vec{w}, \\mathcal{X}, \\beta) & & (p(X, t, \\beta) \\text{ is irrelevant to} \\ \\vec{w})\\\\\n",
    "&= \\arg \\max p(\\vec{t}|\\vec{w}, \\mathcal{X},\\beta) p(\\vec{w}) p(\\mathcal{X}) p(\\beta) & & (\\text{Independence}) \\\\\n",
    "&= \\arg \\max p(\\vec{t}|\\vec{w}, \\mathcal{X},\\beta) p(\\vec{w}) & & (\\text{Likelihood} \\times \\text{Prior})\n",
    "\\end{aligned}\n",
    "$$\n",
    "Here, we assume $\\vec{w} \\sim \\mathcal{N}(\\vec{0}, \\alpha^{-1}I)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 3.2:\n",
    "Suppose that we have already observed $N$ data points, the posterior distribution over $\\vec{w}$ can be regarded as the prior for the next observation. So we can predict the next data point $(\\vec{x}_{N+1}, t_{N+1})$ by maximize $p(t_{N+1}|\\vec{x}_{N+1}, \\vec{X}, \\alpha, \\beta)$. Derive the full expression for the posterior of the new data point.\n",
    "\n",
    "We can also predict the expectation value of $t_{N+1}$ given $\\vec{x}_{N+1}$ by $\\mathbb{E}[t_{N+1}|\\vec{x}_{N+1}]$ using the posterior probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Review: Naive Bayes\n",
    "\n",
    "- The essence of Naive Bayes is the **conditionally independence assumption**\n",
    "    $$\n",
    "    P(\\vec{x} | y = c) = \\prod_{d=1}^D P(x_d | y=c)\n",
    "    $$\n",
    "    i.e., given the label, all features are independent.\n",
    "    \n",
    "- The **full generative** model of Naive Bayes is:\n",
    "    $$\n",
    "    \\begin{align}\n",
    "    y       &\\sim \\mathrm{Categorical}(\\pi) \\\\\n",
    "    x_d | y=c &\\sim \\mathrm{Categorical}(\\theta_{cd}) \\quad \\forall\\, d = 1,\\dots,D\n",
    "    \\end{align}\n",
    "    $$\n",
    "    with parameters:\n",
    "    - $P(y = c) = \\pi_c$, $\\forall c = 1,\\dots,C $\n",
    "    - $\\sum_{c=1}^C \\pi_c = 1$ and $\\pi_c \\geq 0, \\forall c=1,\\dots,C$\n",
    "    - $P(x_d = m| y = c) = \\theta_{cdm}$ for every $d = 1,\\dots,D, m = 1, \\dots, M, c = 1, \\dots, C$\n",
    "    - $\\sum_{m=1}^M \\theta_{cdm} = 1$\n",
    "\n",
    "- Conditional indepence assumption\n",
    "    - Conditional independence: for any $i \\neq j$, $P(X_i | X_j, Y) = P(X_i | Y)$\n",
    "    - The implication is: $P(X_1, \\ldots, X_n | Y) = P(X_1 | X_2, \\ldots, X_n, Y) P(X_2,\\ldots, X_n | Y)$.\n",
    "    - By the Bayes theorem, \n",
    "$$P(Y| X_1, \\ldots, X_n) = \\frac{P(Y)}{P(X_1, \\ldots, X_n)} P(X_1,\\ldots,X_n | Y) = \\frac{P(Y)\\prod_i P(X_i | Y)}{P(X_1,\\ldots, X_n)}$$\n",
    "    - When computing the MAP estimate $P(Y | X_1,\\ldots, X_n)$, we can simply compare the numerator.\n",
    "- Parameter $\\pi$ and $\\theta$ are learned from training data.\n",
    "    - $\\hat{\\pi}_c = \\frac{N_c}{N}$\n",
    "    - $\\hat{\\theta}_{cdm} = \\frac{N_{cdm}}{N_c}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Common problems\n",
    "1. What if not all the words appear in a category, in which case we have $N_{cdm} = 0$?\n",
    "2. What if some attributes are continues variables, not discrete?"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
